{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/Federico6419/Mask-CycleGAN/blob/main/Mask_CycleGAN.ipynb","timestamp":1687344744153},{"file_id":"https://github.com/Federico6419/Mask-CycleGAN/blob/main/Mask_CycleGAN.ipynb","timestamp":1687341522874}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":26,"metadata":{"id":"hx3U35iEAKi2","executionInfo":{"status":"error","timestamp":1687344586354,"user_tz":-120,"elapsed":644,"user":{"displayName":"","userId":""}},"outputId":"44a7c802-92d0-46dc-8250-55058e9a455d","colab":{"base_uri":"https://localhost:8080/","height":356}},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'Mask-CycleGAN' already exists and is not an empty directory.\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-36a2bf69af1d>\u001b[0m in \u001b[0;36m<cell line: 354>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-36a2bf69af1d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;31m############## CHOICE OF THE DATASET ###############  !!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRANSFORMATION\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"WinterToSummer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         dataset = Dataset(\n\u001b[1;32m    308\u001b[0m         \u001b[0mwinter_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/trainWinter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummer_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/trainSummer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'config' has no attribute 'TRANSFORMATION'"]}],"source":["#WINTER = A   !!!!\n","#SUMMER = B\n","\n","!git clone https://github.com/Federico6419/Mask-CycleGAN\n","\n","from dataset import Dataset\n","import config\n","from discriminator import Discriminator\n","from generator import Generator\n","\n","import torch\n","import numpy as np\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision.utils import save_image\n","from torch import Tensor\n","from tqdm import tqdm\n","from torch.autograd import Variable\n","import torch.autograd as autograd\n","from torch.utils.tensorboard import SummaryWriter\n","\n","######### FUNCTION FOR SAVE AND LOAD MODELS #########\n","\n","def save_model(model, optimizer, epoch, filename=\"my_checkpoint.pth.tar\"):\n","    print(\"Saving model for epoch : \"+ str(epoch))\n","\n","    torch.save({\n","        \"state_dict\": model.state_dict(),\n","        \"optimizer\": optimizer.state_dict(),\n","    }, filename)\n","\n","\n","def load_model(file, model, optimizer, lr):\n","    print(\"Loading model: \")\n","    model_check = torch.load(file, map_location=config.DEVICE)\n","    model.load_state_dict(model_check[\"state_dict\"])\n","    optimizer.load_state_dict(model_check[\"optimizer\"])\n","\n","    #epoch =model_check[\"epoch\"]\n","\n","    for param_group in optimizer.param_groups:\n","        param_group[\"lr\"] = lr\n","\n","\n","######### END FUNCTION FOR MODELS ##########\n","\n","def gradient_penalty(model, real_images, fake_images, device):\n","    # Random weight term for interpolation between real and fake data\n","    alpha = torch.randn((real_images.size(0), 1, 1, 1), device=device)\n","    print(alpha)\n","    # Get random interpolation between real and fake data\n","    interpolates = (alpha * real_images + ((1 - alpha) * fake_images)).requires_grad_(True)\n","\n","    model_interpolates = model(interpolates)\n","    grad_outputs = torch.ones(model_interpolates.size(), device=device, requires_grad=False)\n","\n","    # Get gradient w.r.t. interpolates\n","    gradients = torch.autograd.grad(\n","        outputs=model_interpolates,\n","        inputs=interpolates,\n","        grad_outputs=grad_outputs,\n","        create_graph=True,\n","        retain_graph=True,\n","        only_inputs=True,\n","    )[0]\n","    gradients = gradients.view(gradients.size(0), -1)\n","    gradient_penalty = torch.mean((gradients.norm(2, dim=1) - 1) ** 2)\n","    return gradient_penalty\n","\n","\n","\n","                ########################### TRAIN FUNCTION #########################\n","def train_fn(disc_A, disc_B, gen_B, gen_A, loader, opt_disc, opt_gen, l1, mse, BCE, d_scaler, g_scaler,LAMBDA_IDENTITY, LAMBDA_CYCLE,GAMMA_CYCLE):\n","\n","    loop = tqdm(loader, leave=True)           #leave=True to avoid print newline\n","\n","    # Loss weight for gradient penalty\n","    LAMBDA_GP = 10\n","\n","    for idx, (domainB, domainA) in enumerate(loop):\n","        domainA = domainA.to(config.DEVICE)\n","        domainB = domainB.to(config.DEVICE)\n","\n","\n","\n","        # Ground truths used in the adversarial loss\n","        \"\"\"\n","        validA = Variable(Tensor(domainA.shape[0], 1,30,30).fill_(1.0), requires_grad=False)\n","        validB = Variable(Tensor(domainB.shape[0], 1,30,30).fill_(1.0), requires_grad=False)\n","\n","        fakeA = Variable(Tensor(domainA.shape[0], 1,30,30).fill_(0.0), requires_grad=False)\n","        fakeB = Variable(Tensor(domainB.shape[0], 1,30,30).fill_(0.0), requires_grad=False)\n","        \"\"\"\n","\n","        # Label printed every epoch to see the prediction of the discriminators\n","        A_is_real = 0\n","        A_is_fake = 0\n","        B_is_real = 0\n","        B_is_fake = 0\n","\n","\n","        with torch.cuda.amp.autocast():\n","            \"\"\"\n","            validA = validA.to(config.DEVICE)\n","            fakeA = fakeA.to(config.DEVICE)\n","            validB = validB.to(config.DEVICE)\n","            fakeB = fakeB.to(config.DEVICE)\n","            \"\"\"\n","\n","\n","            ############## TRAIN DISCRIMINATOR DOMAIN B #############\n","            fake_B = gen_B(domainA)              #Generate a fake image from domain B starting from an image from domain A\n","\n","            #Compute probability to be a real image from domain B using the discriminator\n","            D_B_real = disc_B(domainB)\n","            D_B_fake = disc_B(fake_B.detach())\n","\n","            #Used to print the percentage that the given image is predicted real or fake !!!!!!!!!!!\n","            B_is_real += D_B_real.mean().item()\n","            B_is_fake += D_B_fake.mean().item()\n","\n","\n","            D_B_real_loss = mse(D_B_real, torch.ones_like(D_B_real))\n","            D_B_fake_loss = mse(D_B_fake, torch.zeros_like(D_B_fake))\n","            D_B_loss = D_B_real_loss + D_B_fake_loss\n","\n","\n","\n","            ########### TRAIN DISCRIMINATOR WINTER ##############\n","            fake_A = gen_A(domainB)\n","            D_A_real = disc_A(domainA)\n","            D_A_fake = disc_A(fake_A.detach())\n","            #used print the percentage that the given image is predicted real or fake\n","            A_is_real += D_A_real.mean().item()\n","            A_is_fake += D_A_fake.mean().item()\n","\n","            D_A_real_loss = mse(D_A_real, torch.ones_like(D_A_real))\n","            D_A_fake_loss = mse(D_A_fake, torch.zeros_like(D_A_fake))\n","            D_A_loss = D_A_real_loss + D_A_fake_loss\n","\n","\n","\n","            # put togheter the loss of the two discriminators\n","            D_loss = (D_A_loss + D_B_loss)/2\n","\n","\n","        opt_disc.zero_grad()\n","        d_scaler.scale(D_loss).backward(retain_graph=True)\n","        d_scaler.step(opt_disc)\n","        d_scaler.update()\n","\n","\n","\n","        ########################## TRAIN GENERATORS #########################\n","        with torch.cuda.amp.autocast():\n","\n","            D_A_fake = disc_A(fake_A)\n","            D_B_fake = disc_B(fake_B)\n","            D_A_real = disc_A(domainA)\n","            D_B_real = disc_B(domainB)\n","\n","            loss_G_A = 0\n","            loss_G_B = 0\n","\n","            loss_G_A = mse(D_A_fake, torch.ones_like(D_A_fake))\n","            loss_G_B = mse(D_B_fake, torch.ones_like(D_B_fake))\n","\n","            \"\"\"\n","            if(config.BETTER):\n","                ################ BETTER CYCLE CONSISTENCY FOLLOWING THE REPORT TIPS #################\n","                cycle_summer = gen_S(fake_winter)\n","                x = disc_S(summer,feature_extract = True)\n","                Fx = disc_S(cycle_summer,feature_extract = True)\n","                norma_summer=l1(x,Fx)\n","                cycle_summer_loss = l1(summer, cycle_summer)\n","\n","                cycle_winter = gen_W(fake_summer)\n","                y = disc_W(winter,feature_extract = True)\n","                Fy = disc_W(cycle_winter,feature_extract = True)\n","                norma_winter=l1(y,Fy)\n","                cycle_winter_loss = l1(winter, cycle_winter)\n","\n","                G_loss = (\n","                loss_G_S\n","                + loss_G_W\n","                + torch.mean(disc_W(winter))*(GAMMA_CYCLE * norma_winter + (1-GAMMA_CYCLE) * cycle_winter_loss) * LAMBDA_CYCLE\n","                + torch.mean(disc_S(summer))*(GAMMA_CYCLE * norma_summer+ (1-GAMMA_CYCLE) * cycle_summer_loss) * LAMBDA_CYCLE\n","                )\n","                ################ BETTER CYCLE CONSISTENCY FOLLOWING THE REPORT TIPS #################\n","            else:\n","              \"\"\"\n","\n","            #CYCLE LOSS\n","            cycle_A = gen_A(fake_A)\n","            cycle_B = gen_B(fake_B)\n","            cycle_A_loss = l1(domainA, cycle_A)\n","            cycle_B_loss = l1(domainB, cycle_B)\n","\n","            #IDENTITY LOSS\n","            identity_A = gen_A(domainA)\n","            identity_B = gen_B(domainB)\n","            identity_loss_A = l1(domainA, identity_A)\n","            identity_loss_B = l1(domainB, identity_B)\n","\n","            #Add all losses together\n","            G_loss = (\n","                loss_G_B\n","                + loss_G_A\n","                + cycle_B_loss * LAMBDA_CYCLE\n","                + cycle_A_loss * LAMBDA_CYCLE\n","                + identity_loss_A * LAMBDA_IDENTITY\n","                + identity_loss_B * LAMBDA_IDENTITY\n","            )\n","\n","\n","        opt_gen.zero_grad()\n","        g_scaler.scale(G_loss).backward(retain_graph=True)\n","        g_scaler.step(opt_gen)\n","        g_scaler.update()\n","\n","        ##########################  END TRAIN GENERATORS #########################\n","\n","\n","        if idx % 150 == 0:    #save tensor into images every 150 to see in real time the progress of the net\n","            save_image(fake_B*0.5+0.5, f\"saved_images/domainB_{idx}.png\")\n","            save_image(fake_A*0.5+0.5, f\"saved_images/domainA_{idx}.png\")\n","\n","        #set postfixes to the progess bar of tqdm\n","        loop.set_postfix(A_real=A_is_real/(idx+1), A_fake=A_is_fake/(idx+1),B_real=B_is_real/(idx+1), B_fake=B_is_fake/(idx+1))\n","\n","                ########################### END TRAIN FUNCTION ######################\n","\n","\n","\n","#TEST FUNCTIONS\n","def test_fn_A(gen_B,gen_A,test_loader):\n","\n","    loop = tqdm(test_loader, leave=True)\n","\n","    for idx, (domainB, domainA) in enumerate(loop):\n","        domainA = domainA.to(config.DEVICE)\n","        domainB = domainB.to(config.DEVICE)\n","        fake_B = gen_B(domainA)\n","        fake_A = gen_A(fake_B)\n","\n","        save_image(domainA*0.5+0.5, f\"test_images/testoriginal_{idx}.png\")\n","        save_image(fake_B*0.5+0.5, f\"test_images/testdomainB_{idx}.png\")\n","        save_image(fake_A*0.5+0.5, f\"test_images/testdomainA_{idx}.png\")\n","\n","def test_fn_B(gen_B,gen_A,test_loader):\n","\n","    loop = tqdm(test_loader, leave=True)\n","\n","    for idx, (domainB, domainA) in enumerate(loop):\n","        domainA = domainA.to(config.DEVICE)\n","        domainB = domainB.to(config.DEVICE)\n","        fake_A = gen_A(domainB)\n","        fake_B = gen_B(fake_A)\n","\n","        save_image(domainB*0.5+0.5, f\"test_images/testoriginal_{idx}.png\")\n","        save_image(fake_B*0.5+0.5, f\"test_images/testdomainB_{idx}.png\")\n","        save_image(fake_A*0.5+0.5, f\"test_images/testdomainA_{idx}.png\")\n","\n","                        ###################### MAIN FUNCTION #######################\n","def main():\n","    disc_A = Discriminator(in_channels=3).to(config.DEVICE)\n","    disc_B = Discriminator(in_channels=3).to(config.DEVICE)\n","    gen_A = Generator(img_channels=3).to(config.DEVICE)\n","    gen_B = Generator(img_channels=3).to(config.DEVICE)\n","\n","    opt_disc = optim.Adam(\n","        list(disc_A.parameters()) + list(disc_B.parameters()),\n","        lr=config.LEARNING_RATE,\n","        betas=(0.5, 0.999),\n","    )\n","\n","    opt_gen = optim.Adam(\n","        list(gen_B.parameters()) + list(gen_A.parameters()),\n","        lr=config.LEARNING_RATE,\n","        betas=(0.5, 0.999),\n","    )\n","\n","    L1 = nn.L1Loss()\n","    mse = nn.MSELoss()\n","    BCE = torch.nn.BCEWithLogitsLoss()\n","\n","    #GAMMA_CYCLE = config.GAMMA_CYCLE # ratio between discriminator CNN feature level and pixel level loss   !!!!!\n","\n","    if config.LOAD_MODEL:\n","        \"\"\"load_model(      !!!!\n","            config.CHECKPOINT_GEN_A, gen_A, opt_gen, config.LEARNING_RATE,\n","        )\n","        load_model(\n","            config.CHECKPOINT_GEN_B, gen_B, opt_gen, config.LEARNING_RATE,\n","        )\n","        load_model(\n","            config.CHECKPOINT_DISC_A, disc_A, opt_disc, config.LEARNING_RATE,\n","        )\n","        load_model(\n","            config.CHECKPOINT_DISC_B, disc_B, opt_disc, config.LEARNING_RATE,\n","        )\"\"\"\n","\n","\n","    ############## CHOICE OF THE DATASET ###############  !!!!\n","    if(config.TRANSFORMATION == \"WinterToSummer\"):\n","        dataset = Dataset(\n","        winter_dir=config.TRAIN_DIR+\"/trainWinter\", summer_dir=config.TRAIN_DIR+\"/trainSummer\", transform=config.transforms\n","        )\n","        test_dataset = Dataset(\n","        winter_dir=config.TEST_DIR+\"/testWinter\", summer_dir=config.TEST_DIR+\"/testSummer\", transform=config.transforms\n","        )\n","\n","     ############# CHOICE OF THE DATASET ##############\n","\n","    ############# DATALOADER #############\n","    loader = DataLoader(\n","        dataset,\n","        batch_size=1,\n","        shuffle=True,\n","        num_workers=4,\n","        pin_memory=True  #for faster training(non-paged cpu memory)\n","    )\n","    test_loader = DataLoader(\n","        test_dataset,\n","        batch_size=1,\n","        shuffle=False,\n","        pin_memory=True,\n","    )\n","    ############# DATALOADER ###############\n","\n","    g_scaler = torch.cuda.amp.GradScaler()\n","    d_scaler = torch.cuda.amp.GradScaler()\n","\n","    if(config.TRAIN_MODEL):\n","\n","        for epoch in range(config.NUM_EPOCHS):\n","            #if(config.BETTER): !!!!\n","                #train_fn(disc_W, disc_S, gen_S, gen_W, loader, opt_disc, opt_gen, L1, mse, BCE, d_scaler, g_scaler,config.LAMBDA_IDENTITY, config.LAMBDA_CYCLE-epoch*0.15,GAMMA_CYCLE=GAMMA_CYCLE+0.015)\n","            #else:\n","            train_fn(disc_A, disc_B, gen_B, gen_A, loader, opt_disc, opt_gen, L1, mse, BCE, d_scaler, g_scaler,config.LAMBDA_IDENTITY, config.LAMBDA_CYCLE, 0)\n","\n","\n","            if config.SAVE_MODEL: #if save_Model is set to true save model on the specific path\n","                save_model(gen_A, opt_gen, epoch ,filename=config.CHECKPOINT_GEN_A)\n","                save_model(gen_B, opt_gen, epoch , filename=config.CHECKPOINT_GEN_B)\n","                save_model(disc_A, opt_disc, epoch , filename=config.CHECKPOINT_DISC_A)\n","                save_model(disc_B, opt_disc, epoch , filename=config.CHECKPOINT_DISC_B)\n","    else:\n","\n","        test_fn_A(gen_B,gen_A,test_loader)\n","        #test_fn_B(gen_B,gen_A,test_loader)\n","\n","if __name__ == \"__main__\":\n","    main()\n","\n"]}]}
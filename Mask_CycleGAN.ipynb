{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hx3U35iEAKi2",
        "outputId": "1d7e926e-950d-405f-bd12-035ee4ef690a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mask-CycleGAN'...\n",
            "remote: Enumerating objects: 5410, done.\u001b[K\n",
            "remote: Counting objects: 100% (94/94), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Federico6419/Mask-CycleGAN          #It clones our github repository\n",
        "%cd Mask-CycleGAN\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#IMPORTS\n",
        "from dataset import Dataset\n",
        "import config\n",
        "from discriminator import Discriminator\n",
        "from generator import Generator\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.utils import save_image\n",
        "from torch import Tensor\n",
        "from tqdm import tqdm\n",
        "from torch.autograd import Variable\n",
        "import torch.autograd as autograd\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "######### FUNCTIONS FOR SAVE AND LOAD MODELS #########\n",
        "#This function saves the weights of the model in a file\n",
        "def save_model(model, optimizer, epoch, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"Saving model for epoch : \"+ str(epoch))\n",
        "\n",
        "    torch.save({\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }, filename)\n",
        "\n",
        "\n",
        "#This function loads the precomputed weights of the model from a file\n",
        "def load_model(file, model, optimizer, lr):\n",
        "    print(\"Loading model: \")\n",
        "    model_check = torch.load(file, map_location=config.DEVICE)\n",
        "    model.load_state_dict(model_check[\"state_dict\"])\n",
        "    optimizer.load_state_dict(model_check[\"optimizer\"])\n",
        "\n",
        "    #epoch =model_check[\"epoch\"]\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n",
        "\n",
        "######### END FUNCTIONS FOR SAVE AND LOAD MODELS ##########\n",
        "\n",
        "\n",
        "\n",
        "########################### TRAIN FUNCTION #########################\n",
        "def train_fn(disc_A, disc_B, gen_B, gen_A, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler,LAMBDA_IDENTITY, LAMBDA_CYCLE,GAMMA_CYCLE):\n",
        "\n",
        "    loop = tqdm(loader, leave=True)           #leave=True to avoid print newline\n",
        "\n",
        "    for idx, (domainB, domainA) in enumerate(loop):                             #It loops over the images from domain A and domain B\n",
        "        domainA = domainA.to(config.DEVICE)                                     #Its puts the images from the two domains one the device\n",
        "        domainB = domainB.to(config.DEVICE)\n",
        "\n",
        "        #Label printed every epoch to see the prediction of the discriminators\n",
        "        A_is_real = 0\n",
        "        A_is_fake = 0\n",
        "        B_is_real = 0\n",
        "        B_is_fake = 0\n",
        "\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "\n",
        "            ############## TRAIN DISCRIMINATOR DOMAIN B #############\n",
        "            fake_B = gen_B(domainA)              #Generate with Generator a fake image from domain B starting from an image from domain A\n",
        "\n",
        "            #Compute probability of the real image and of the fake image to be a real image from domain B using the Discriminator\n",
        "            D_B_real = disc_B(domainB)\n",
        "            D_B_fake = disc_B(fake_B.detach())\n",
        "\n",
        "            #Used to print the percentage that the given image is predicted real or fake !!!!\n",
        "            B_is_real += D_B_real.mean().item()\n",
        "            B_is_fake += D_B_fake.mean().item()\n",
        "\n",
        "            #Compute the Mean Squared Error\n",
        "            D_B_real_loss = mse(D_B_real, torch.ones_like(D_B_real))    #MSE computed between the prediction of the real image made by Discriminator and a Tensor composed by all ones\n",
        "            D_B_fake_loss = mse(D_B_fake, torch.zeros_like(D_B_fake))   #MSE computed between the prediction of the fake image made by Discriminator and a Tensor composed by all zeros\n",
        "            D_B_loss = D_B_real_loss + D_B_fake_loss                    #Sum the real image loss and the fake image loss\n",
        "\n",
        "\n",
        "\n",
        "            ########### TRAIN DISCRIMINATOR OF THE DOMAIN A ##############\n",
        "            fake_A = gen_A(domainB)             #Generate with Generator a fake image from domain A starting from an image from domain B\n",
        "\n",
        "            #Compute probability of the real image and of the fake image to be a real image from domain B using the Discriminator\n",
        "            D_A_real = disc_A(domainA)\n",
        "            D_A_fake = disc_A(fake_A.detach())\n",
        "\n",
        "            #Used print the percentage that the given image is predicted real or fake !!!!\n",
        "            A_is_real += D_A_real.mean().item()\n",
        "            A_is_fake += D_A_fake.mean().item()\n",
        "\n",
        "            #Compute the Mean Squared Error\n",
        "            D_A_real_loss = mse(D_A_real, torch.ones_like(D_A_real))    #MSE computed between the prediction of the real image made by Discriminator and a Tensor composed by all ones\n",
        "            D_A_fake_loss = mse(D_A_fake, torch.zeros_like(D_A_fake))   #MSE computed between the prediction of the fake image made by Discriminator and a Tensor composed by all zeros\n",
        "            D_A_loss = D_A_real_loss + D_A_fake_loss                    #Sum the real image loss and the fake image loss\n",
        "\n",
        "\n",
        "\n",
        "            #Put together the loss of the two discriminators\n",
        "            D_loss = (D_A_loss + D_B_loss)/2\n",
        "\n",
        "\n",
        "        opt_disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward(retain_graph=True)\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "\n",
        "\n",
        "        ########################## TRAIN GENERATORS #########################\n",
        "        with torch.cuda.amp.autocast():\n",
        "\n",
        "            #Compute the Discriminator predictions\n",
        "            D_A_fake = disc_A(fake_A)\n",
        "            D_B_fake = disc_B(fake_B)\n",
        "            D_A_real = disc_A(domainA)\n",
        "            D_B_real = disc_B(domainB)\n",
        "\n",
        "            #Compute the GAN losses\n",
        "            loss_G_A = 0\n",
        "            loss_G_B = 0\n",
        "\n",
        "            loss_G_A = mse(D_A_fake, torch.ones_like(D_A_fake))  #Compute the MSE between the prediction of the Discriminator of the fake image from domain A and a tensor with all ones\n",
        "            loss_G_B = mse(D_B_fake, torch.ones_like(D_B_fake))  #Compute the MSE between the prediction of the Discriminator of the fake image from domain B and a tensor with all ones\n",
        "\n",
        "            \"\"\"\n",
        "            #BETTER CYCLE CONSISTENCY\n",
        "            if(config.BETTER):\n",
        "                ################ BETTER CYCLE CONSISTENCY FOLLOWING THE REPORT TIPS #################\n",
        "                cycle_summer = gen_S(fake_winter)\n",
        "                x = disc_S(summer,feature_extract = True)\n",
        "                Fx = disc_S(cycle_summer,feature_extract = True)\n",
        "                norma_summer=l1(x,Fx)\n",
        "                cycle_summer_loss = l1(summer, cycle_summer)\n",
        "\n",
        "                cycle_winter = gen_W(fake_summer)\n",
        "                y = disc_W(winter,feature_extract = True)\n",
        "                Fy = disc_W(cycle_winter,feature_extract = True)\n",
        "                norma_winter=l1(y,Fy)\n",
        "                cycle_winter_loss = l1(winter, cycle_winter)\n",
        "\n",
        "                G_loss = (\n",
        "                loss_G_S\n",
        "                + loss_G_W\n",
        "                + torch.mean(disc_W(winter))*(GAMMA_CYCLE * norma_winter + (1-GAMMA_CYCLE) * cycle_winter_loss) * LAMBDA_CYCLE\n",
        "                + torch.mean(disc_S(summer))*(GAMMA_CYCLE * norma_summer+ (1-GAMMA_CYCLE) * cycle_summer_loss) * LAMBDA_CYCLE\n",
        "                )\n",
        "                ################ BETTER CYCLE CONSISTENCY FOLLOWING THE REPORT TIPS #################\n",
        "            else:\n",
        "              \"\"\"\n",
        "\n",
        "            #CYCLE LOSS\n",
        "            cycle_A = gen_A(fake_A)\n",
        "            cycle_B = gen_B(fake_B)\n",
        "            cycle_A_loss = l1(domainA, cycle_A)\n",
        "            cycle_B_loss = l1(domainB, cycle_B)\n",
        "\n",
        "            #IDENTITY LOSS\n",
        "            identity_A = gen_A(domainA)\n",
        "            identity_B = gen_B(domainB)\n",
        "            identity_loss_A = l1(domainA, identity_A)\n",
        "            identity_loss_B = l1(domainB, identity_B)\n",
        "\n",
        "            #Add all losses together, multiplied by their relative parameter\n",
        "            G_loss = (\n",
        "                loss_G_B\n",
        "                + loss_G_A\n",
        "                + cycle_B_loss * LAMBDA_CYCLE\n",
        "                + cycle_A_loss * LAMBDA_CYCLE\n",
        "                + identity_loss_A * LAMBDA_IDENTITY\n",
        "                + identity_loss_B * LAMBDA_IDENTITY\n",
        "            )\n",
        "\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward(retain_graph=True)\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "\n",
        "        ##########################  END TRAIN GENERATORS #########################\n",
        "\n",
        "\n",
        "        #Save tensors into images every 150 to see in real time the progress of the net\n",
        "        if idx % 150 == 0:\n",
        "            save_image(fake_B*0.5+0.5, f\"Saved_Images/domainB_{idx}.png\")\n",
        "            save_image(fake_A*0.5+0.5, f\"Saved_Images/domainA_{idx}.png\")\n",
        "\n",
        "        #Set postfixes to the progess bar of tqdm\n",
        "        loop.set_postfix(A_real=A_is_real/(idx+1), A_fake=A_is_fake/(idx+1),B_real=B_is_real/(idx+1), B_fake=B_is_fake/(idx+1))\n",
        "\n",
        "########################### END TRAIN FUNCTION ######################\n",
        "\n",
        "\n",
        "\n",
        "#TEST FUNCTIONS\n",
        "#Test function for Domain A\n",
        "def test_fn_A(gen_B, gen_A, test_loader):\n",
        "\n",
        "    loop = tqdm(test_loader, leave=True)\n",
        "\n",
        "    for idx, (domainB, domainA) in enumerate(loop):\n",
        "        domainA = domainA.to(config.DEVICE)\n",
        "        domainB = domainB.to(config.DEVICE)\n",
        "        fake_B = gen_B(domainA)\n",
        "        fake_A = gen_A(fake_B)\n",
        "\n",
        "        save_image(domainA*0.5+0.5, f\"test_images/testoriginal_{idx}.png\")\n",
        "        save_image(fake_B*0.5+0.5, f\"test_images/testdomainB_{idx}.png\")\n",
        "        save_image(fake_A*0.5+0.5, f\"test_images/testdomainA_{idx}.png\")\n",
        "\n",
        "#Test function for Domain B\n",
        "def test_fn_B(gen_B,gen_A,test_loader):\n",
        "\n",
        "    loop = tqdm(test_loader, leave=True)\n",
        "\n",
        "    for idx, (domainB, domainA) in enumerate(loop):\n",
        "        domainA = domainA.to(config.DEVICE)\n",
        "        domainB = domainB.to(config.DEVICE)\n",
        "        fake_A = gen_A(domainB)\n",
        "        fake_B = gen_B(fake_A)\n",
        "\n",
        "        save_image(domainB*0.5+0.5, f\"test_images/testoriginal_{idx}.png\")\n",
        "        save_image(fake_B*0.5+0.5, f\"test_images/testdomainB_{idx}.png\")\n",
        "        save_image(fake_A*0.5+0.5, f\"test_images/testdomainA_{idx}.png\")\n",
        "\n",
        "\n",
        "###################### MAIN FUNCTION #######################\n",
        "def main():\n",
        "    disc_A = Discriminator(in_channels=3).to(config.DEVICE)\n",
        "    disc_B = Discriminator(in_channels=3).to(config.DEVICE)\n",
        "    gen_A = Generator(img_channels=3).to(config.DEVICE)\n",
        "    gen_B = Generator(img_channels=3).to(config.DEVICE)\n",
        "\n",
        "    opt_disc = optim.Adam(\n",
        "        list(disc_A.parameters()) + list(disc_B.parameters()),\n",
        "        lr=config.LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    opt_gen = optim.Adam(\n",
        "        list(gen_B.parameters()) + list(gen_A.parameters()),\n",
        "        lr=config.LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    L1 = nn.L1Loss()\n",
        "    mse = nn.MSELoss()\n",
        "\n",
        "    #GAMMA_CYCLE = config.GAMMA_CYCLE # ratio between discriminator CNN feature level and pixel level loss   !!!!!\n",
        "\n",
        "    if config.LOAD_MODEL:\n",
        "        load_model(\n",
        "            config.CHECKPOINT_GEN_A, gen_A, opt_gen, config.LEARNING_RATE,\n",
        "        )\n",
        "        load_model(\n",
        "            config.CHECKPOINT_GEN_B, gen_B, opt_gen, config.LEARNING_RATE,\n",
        "        )\n",
        "        load_model(\n",
        "            config.CHECKPOINT_DISC_A, disc_A, opt_disc, config.LEARNING_RATE,\n",
        "        )\n",
        "        load_model(\n",
        "            config.CHECKPOINT_DISC_B, disc_B, opt_disc, config.LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "\n",
        "    ############## CHOICE OF THE DATASET ###############  !!!!\n",
        "    if(config.TRANSFORMATION == \"WinterToSummer\"):\n",
        "        dataset = Dataset(\n",
        "            domainA_dir=config.TRAIN_DIR+\"/trainWinter\", domainB_dir=config.TRAIN_DIR+\"/trainSummer\", transform=config.transforms\n",
        "        )\n",
        "        test_dataset = Dataset(\n",
        "            domainA_dir=config.TEST_DIR+\"/testWinter\", domainB_dir=config.TEST_DIR+\"/testSummer\", transform=config.transforms\n",
        "        )\n",
        "    elif(config.TRANSFORMATION == \"HorseToZebra\"):\n",
        "        dataset = Dataset(\n",
        "            domainA_dir=config.TRAIN_DIR+\"/trainHorse\", domainB_dir=config.TRAIN_DIR+\"/trainZebra\", transform=config.transforms\n",
        "        )\n",
        "        test_dataset = Dataset(\n",
        "            domainA_dir=config.TEST_DIR+\"/testHorse\", domainB_dir=config.TEST_DIR+\"/testZebra\", transform=config.transforms\n",
        "        )\n",
        "\n",
        "     ############# CHOICE OF THE DATASET ##############\n",
        "\n",
        "    ############# DATALOADER #############\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=1,\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        pin_memory=True  #for faster training(non-paged cpu memory)\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=1,\n",
        "        shuffle=False,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    ############# DATALOADER ###############\n",
        "\n",
        "    g_scaler = torch.cuda.amp.GradScaler()\n",
        "    d_scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    if(config.TRAIN_MODEL):\n",
        "\n",
        "        for epoch in range(config.NUM_EPOCHS):\n",
        "            #if(config.BETTER): !!!!\n",
        "                #train_fn(disc_W, disc_S, gen_S, gen_W, loader, opt_disc, opt_gen, L1, mse, d_scaler, g_scaler,config.LAMBDA_IDENTITY, config.LAMBDA_CYCLE-epoch*0.15,GAMMA_CYCLE=GAMMA_CYCLE+0.015)\n",
        "            #else:\n",
        "            train_fn(disc_A, disc_B, gen_B, gen_A, loader, opt_disc, opt_gen, L1, mse, d_scaler, g_scaler,config.LAMBDA_IDENTITY, config.LAMBDA_CYCLE, 0)\n",
        "\n",
        "\n",
        "            if config.SAVE_MODEL: #if save_Model is set to true save model on the specific path\n",
        "                save_model(gen_A, opt_gen, epoch ,filename=config.NEW_CHECKPOINT_GEN_A)\n",
        "                save_model(gen_B, opt_gen, epoch , filename=config.NEW_CHECKPOINT_GEN_B)\n",
        "                save_model(disc_A, opt_disc, epoch , filename=config.NEW_CHECKPOINT_DISC_A)\n",
        "                save_model(disc_B, opt_disc, epoch , filename=config.NEW_CHECKPOINT_DISC_B)\n",
        "    else:\n",
        "\n",
        "        test_fn_A(gen_B,gen_A,test_loader)\n",
        "        #test_fn_B(gen_B,gen_A,test_loader)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    }
  ]
}